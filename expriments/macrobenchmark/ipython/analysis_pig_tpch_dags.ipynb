{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/local0/Kariz/expriments/macrobenchmark/ipython\n",
      "{\"['Q1', 'sequential']\": <Graph object, directed, with 4 vertices and 3 edges at 0x7f6cf4cf8630>, \"['Q2', 'sequential']\": <Graph object, directed, with 8 vertices and 7 edges at 0x7f6cf4d05198>, \"['Q3', 'sequential']\": <Graph object, directed, with 6 vertices and 5 edges at 0x7f6cf4d05278>}\n"
     ]
    }
   ],
   "source": [
    "import code.utils.graph\n",
    "import graph_tool.all as gt\n",
    "import os\n",
    "import ast\n",
    "import re\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "def build_input_format(inputs_str):\n",
    "    res = re.search('\\[(.*)\\]', inputs_str)\n",
    "    return dict.fromkeys(res.group(1).split(','), 0) if res else {}\n",
    "    \n",
    "\n",
    "def build_graph_skeleton(g_str):\n",
    "    g_elements = g_str.split('\\n')\n",
    "    g_name = g_elements[0].split(',')[1:]\n",
    "    g_id = 0\n",
    "    g_queuetime = 0\n",
    "    \n",
    "    g = gt.Graph(directed=True)\n",
    "    g.gp['name'] = g.new_graph_property(\"string\", g_name)\n",
    "    g.gp['id'] = g.new_graph_property(\"string\", str(g_id))\n",
    "    g.gp['queue_time'] = g.new_graph_property(\"int\", g_queuetime)\n",
    "    g.gp['cur_stage'] = g.new_graph_property(\"int\", -1)\n",
    "    status = g.new_vertex_property(\"int\")\n",
    "    inputs = g.new_vertex_property(\"object\")\n",
    "    cache_runtime = g.new_vertex_property(\"int\")\n",
    "    remote_runtime = g.new_vertex_property(\"int\")\n",
    "    ops = g.new_vertex_property(\"vector<string>\")\n",
    "\n",
    "    # build vertices\n",
    "    for el in g_elements[1:]:\n",
    "        if el.startswith('v'):\n",
    "            vid, inputs_str, operation = el.split(',')[1:]\n",
    "            v = g.add_vertex()\n",
    "            \n",
    "            inputs[v] = build_input_format(inputs_str)\n",
    "            cache_runtime[v] = 0\n",
    "            remote_runtime[v] = 0 \n",
    "            ops[v] = operation.split('|')\n",
    "    \n",
    "    # build edges\n",
    "    for el in g_elements[1:]:\n",
    "        if el.startswith('e'):\n",
    "            v_src, v_dest = el.split(',')[1:]\n",
    "            e = g.add_edge(v_src, v_dest)\n",
    "    return g\n",
    "            \n",
    "\n",
    "def load_graph_skeleton(path):\n",
    "    graph_skeletons = {}\n",
    "    with open(path, 'r') as fd:\n",
    "        graph_strs = fd.read().split('#')[1:]\n",
    "\n",
    "        for g_str in graph_strs:\n",
    "            g= build_graph_skeleton(g_str)\n",
    "            graph_skeletons[g.gp.name] = g\n",
    "    return graph_skeletons\n",
    "            \n",
    "path = \"../tpch_pig_dags.g\"\n",
    "graph_skeletons = load_graph_skeleton(path)\n",
    "\n",
    "print(graph_skeletons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/local0/Kariz/expriments/macrobenchmark/ipython\n",
      "{\n",
      "  \"type\": \"sequential\",\n",
      "  \"graph_src\": \"file\",\n",
      "  \"graph_skeleton_path\": \"/local0/Kariz/expriments/macrobenchmark/tpch_pig_dags.g\",\n",
      "  \"stat_file_path\": \"/local0/Kariz/expriments/macrobenchmark/pig_tpch_stats\",\n",
      "  \"input_dir\": \"s3a://data/pig-tpch/64G\",\n",
      "  \"output_dir\": \"/tpch-64G-output\",\n",
      "  \"benchmark_path\": \"/local0/Kariz/expriments/benchmark/BenchmarkScripts/tpch/pig\"\n",
      "}\n",
      "{'Q1': <Graph object, directed, with 4 vertices and 3 edges at 0x7ff09e0a3198>, 'Q2': <Graph object, directed, with 8 vertices and 7 edges at 0x7ff09e0a3160>, 'Q3': <Graph object, directed, with 6 vertices and 5 edges at 0x7ff09e0a3940>}\n"
     ]
    }
   ],
   "source": [
    "import code.utils.graph\n",
    "import graph_tool.all as gt\n",
    "import os\n",
    "import ast\n",
    "import re\n",
    "\n",
    "import workload.sequential as sqw\n",
    "import sys\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "config_file = \"../config.json\"\n",
    "\n",
    "workload = sqw.Sequential(config_file)\n",
    "\n",
    "print(workload.graph_skeleton_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/local0/Kariz/expriments/macrobenchmark/pig_tpch_stats\n"
     ]
    }
   ],
   "source": [
    "# Load statistics\n",
    "import utils.jobhistory as hist\n",
    "import pandas as pd\n",
    "\n",
    "print(workload.configs['stat_file_path'])\n",
    "\n",
    "jobs_stats = pd.read_csv(workload.configs['stat_file_path'])\n",
    "\n",
    "jobs_stats = jobs_stats[jobs_stats['runtime'] == 0].apply(hist.process_tasks, axis=1)\n",
    "\n",
    "jobs_stats.to_csv(workload.configs['stat_file_path'], index=False, header=True)\n",
    "#jobs = jobs.apply(process_tasks, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
