{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhive import hive\n",
    "from TCLIService.ttypes import TOperationState\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import ast\n",
    "import json\n",
    "import graph_tool.all as gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-b64f8e3385f4>, line 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-b64f8e3385f4>\"\u001b[0;36m, line \u001b[0;32m24\u001b[0m\n\u001b[0;31m    cursor.execute(query, async=False)\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def is_float(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def parse_settings(setting):\n",
    "    prop, value = setting.split(' ')[1].split('=')\n",
    "    if value.isnumeric():\n",
    "        return prop, int(value)\n",
    "    elif is_float(value):\n",
    "        return prop, float(value)\n",
    "    return prop, value\n",
    "\n",
    "def apply(setting):\n",
    "    prop, value = setting\n",
    "    if isinstance(value, int):\n",
    "        query = 'set %s=%d'%(prop, value)\n",
    "    elif isinstance(value, float): \n",
    "        query = 'set %s=%f'%(prop, value)\n",
    "    else:\n",
    "        query = 'set %s=%s'%(prop, value)\n",
    "    cursor.execute(query, async=False)\n",
    "\n",
    "def process_tree(tree):\n",
    "    if not tree: return ''\n",
    "    for op in tree:\n",
    "        if 'children' not in tree[op]: \n",
    "            return op.replace(' Operator', '')\n",
    "        return op.replace(' Operator', '') + ' | ' + process_tree(tree[op]['children'])\n",
    "\n",
    "# Parse the insert query\n",
    "def parse_table_op_tree(table_tree, metadata):\n",
    "    for o in table_tree:\n",
    "        if o == 'TableScan':\n",
    "            if 'table:' in table_tree[o]:\n",
    "                metadata['in_table'] = table_tree[o]['table:']\n",
    "        metadata['ops'].append(o.replace(' Operator', ''))\n",
    "        if 'children' in table_tree[o]:\n",
    "            parse_table_op_tree(table_tree[o]['children'], metadata)\n",
    "\n",
    "\n",
    "def graph_annotation(annotations_tree):\n",
    "    exec_plan = annotations_tree\n",
    "   \n",
    "    metadata = {}\n",
    "    for stg_id in exec_plan:\n",
    "        stg_plan = exec_plan[stg_id]\n",
    "        for stg_op in stg_plan:\n",
    "            op_works = stg_plan[stg_op]\n",
    "\n",
    "            metadata[stg_id] = {'ops': []}\n",
    "            if stg_op == \"Stats-Aggr Operator\":\n",
    "                metadata[stg_id]['ops'].append(stg_op.replace(' Operator', ''))\n",
    "            elif stg_op == \"Move Operator\":\n",
    "                metadata[stg_id]['ops'].append(stg_op.replace(' Operator', ''))\n",
    "                metadata[stg_id]['out_table'] =  op_works['tables:']['table:'][\"name:\"]\n",
    "            elif stg_op in ['Map Reduce', 'Map Reduce Local Work']:        \n",
    "                for op in op_works:\n",
    "                    if op in [\"Alias -> Map Local Operator Tree:\", \"Alias -> Map Local Tables:\"]:\n",
    "                        op_tree = op_works[op]\n",
    "                        for table_name in op_tree:\n",
    "                            parse_table_op_tree(op_tree[table_name], metadata[stg_id])\n",
    "                    elif op == \"Map Operator Tree:\":\n",
    "                        op_tree = op_works[op][0]\n",
    "                        parse_table_op_tree(op_tree, metadata[stg_id])\n",
    "    return metadata\n",
    "\n",
    "\n",
    "def build_graph_from_execution_plan(explain_cmd_json):\n",
    "    execution_plan = explain_cmd_json['STAGE DEPENDENCIES']\n",
    "    annotations_tree = graph_annotation(explain_cmd_json['STAGE PLANS'])\n",
    "\n",
    "    label_vid_map = {}\n",
    "    g = gt.Graph(directed=True)\n",
    "    g.vertex_properties['label'] = g.new_vertex_property(\"string\")\n",
    "    g.vertex_properties['ops'] = g.new_vertex_property(\"vector<string>\")\n",
    "    g.vertex_properties['ext_input'] = g.new_vertex_property(\"string\")\n",
    "    \n",
    "    for sid in execution_plan:\n",
    "        if sid not in label_vid_map:\n",
    "            vid = g.add_vertex()\n",
    "            label_vid_map[sid] = vid\n",
    "            g.vp.label[vid] = sid\n",
    "            g.vp.ops[vid] = annotations_tree[sid]['ops']\n",
    "            #print(annotations_tree[sid])\n",
    "        \n",
    "    for sid in execution_plan:\n",
    "        if 'DEPENDENT STAGES' in execution_plan[sid]:\n",
    "            dep_stages = [g.add_edge(label_vid_map[dsid], label_vid_map[sid]) for dsid in execution_plan[sid]['DEPENDENT STAGES'].replace(' ', '').split(',')]; dep_stages\n",
    "        if 'CONDITIONAL CHILD TASKS' in execution_plan[sid]:\n",
    "            dep_stages = [g.add_edge(label_vid_map[sid], label_vid_map[dsid]) for dsid in execution_plan[sid]['CONDITIONAL CHILD TASKS'].replace(' ', '').split(',')]; dep_stages\n",
    "    return g\n",
    "\n",
    "\n",
    "def main():\n",
    "    cursor = hive.connect('neu-3-1').cursor() \n",
    "\n",
    "    # hive configuration file\n",
    "    benchmark_path = '/local0/Kariz/expriments/benchmark/hive-testbench/sample-queries-tpcds'\n",
    "    queries = ['%s/%s'%(benchmark_path, f) for f in listdir(benchmark_path) if (f.endswith(\".sql\") and isfile(join(benchmark_path, f)))]\n",
    "    queries.sort()\n",
    "\n",
    "    with open('%s/testbench.settings'%(benchmark_path), 'r') as fd:\n",
    "        apply_settings = [apply(parse_settings(query)) for query in fd.read().split(';\\n')[:-1]]; apply_settings\n",
    "\n",
    "    query = 'use tpcds_bin_partitioned_textfile_10'\n",
    "    cursor.execute(query, async=False)\n",
    "\n",
    "    for index, query_file in enumerate(queries): \n",
    "        with open(query_file, 'r') as fd:\n",
    "            if index == 46:\n",
    "                continue;\n",
    "            print(index, query_file.split('/')[-1].split('.')[0])\n",
    "            query = 'EXPLAIN FORMATTED %s'%(fd.read().replace(';', ''))\n",
    "            cursor.execute(query, async=False)\n",
    "            res = cursor.fetchall()\n",
    "            explain_cmd_json = json.loads(res[0][0])\n",
    "            g = build_graph_from_execution_plan(explain_cmd_json)\n",
    "            print('\\t', g.num_vertices(), g.num_edges())\n",
    "            gt.graph_draw(g, vertex_text=g.vertex_index, \n",
    "                          output='%s.png'%(query_file.split('/')[-1].split('.')[0]),\n",
    "                          output_size=(1000, 1000))\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
