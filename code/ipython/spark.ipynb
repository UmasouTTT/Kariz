{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# api-endpoint \n",
    "\n",
    "URL = \"http://neu-3-1:18080/api/v1/applications\"\n",
    "\n",
    "\n",
    "# sending get request and saving the response as response object \n",
    "r = requests.get(url = URL) \n",
    "  \n",
    "# extracting data in json format \n",
    "applications = r.json() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app-20200617160405-0036\n",
      "http://neu-3-1:18080/api/v1/applications/app-20200617160405-0036/stages\n",
      "<Response [200]>\n",
      "1 0 26655 [6, 5] 64 7.0\n",
      "dict_keys(['status', 'stageId', 'attemptId', 'numTasks', 'numActiveTasks', 'numCompleteTasks', 'numFailedTasks', 'numKilledTasks', 'numCompletedIndices', 'submissionTime', 'firstTaskLaunchedTime', 'completionTime', 'executorDeserializeTime', 'executorDeserializeCpuTime', 'executorRunTime', 'executorCpuTime', 'resultSize', 'jvmGcTime', 'resultSerializationTime', 'memoryBytesSpilled', 'diskBytesSpilled', 'peakExecutionMemory', 'inputBytes', 'inputRecords', 'outputBytes', 'outputRecords', 'shuffleRemoteBlocksFetched', 'shuffleLocalBlocksFetched', 'shuffleFetchWaitTime', 'shuffleRemoteBytesRead', 'shuffleRemoteBytesReadToDisk', 'shuffleLocalBytesRead', 'shuffleReadBytes', 'shuffleReadRecords', 'shuffleWriteBytes', 'shuffleWriteTime', 'shuffleWriteRecords', 'name', 'details', 'schedulingPool', 'rddIds', 'accumulatorUpdates', 'killedTasksSummary'])\n",
      "0 1102238868 0 [4, 3, 1, 0, 2] 8 9.0\n",
      "dict_keys(['status', 'stageId', 'attemptId', 'numTasks', 'numActiveTasks', 'numCompleteTasks', 'numFailedTasks', 'numKilledTasks', 'numCompletedIndices', 'submissionTime', 'firstTaskLaunchedTime', 'completionTime', 'executorDeserializeTime', 'executorDeserializeCpuTime', 'executorRunTime', 'executorCpuTime', 'resultSize', 'jvmGcTime', 'resultSerializationTime', 'memoryBytesSpilled', 'diskBytesSpilled', 'peakExecutionMemory', 'inputBytes', 'inputRecords', 'outputBytes', 'outputRecords', 'shuffleRemoteBlocksFetched', 'shuffleLocalBlocksFetched', 'shuffleFetchWaitTime', 'shuffleRemoteBytesRead', 'shuffleRemoteBytesReadToDisk', 'shuffleLocalBytesRead', 'shuffleReadBytes', 'shuffleReadRecords', 'shuffleWriteBytes', 'shuffleWriteTime', 'shuffleWriteRecords', 'name', 'details', 'schedulingPool', 'rddIds', 'accumulatorUpdates', 'killedTasksSummary'])\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "import datetime \n",
    "\n",
    "def get_stages(app_id):\n",
    "    print(app_id)\n",
    "    URL = \"http://neu-3-1:18080/api/v1/applications/%s/stages\"%(app_id)\n",
    "    # sending get request and saving the response as response object \n",
    "    if URL == \"http://neu-3-1:18080/api/v1/applications/app-20200617160405-0036/stages\":\n",
    "        print(URL)\n",
    "        \n",
    "    URL=\"http://neu-3-1:18080/api/v1/applications/app-20200617160405-0036/stages\"\n",
    "        \n",
    "    r = requests.get(url = URL) \n",
    "    print(r)\n",
    "    # extracting data in json format \n",
    "    stages = r.json() \n",
    "\n",
    "    for s in stages:\n",
    "        submit_time = time.mktime(datetime.datetime.strptime(s['submissionTime'], \n",
    "                                                     \"%Y-%m-%dT%H:%M:%S.%fGMT\").timetuple())        \n",
    "        start_time = time.mktime(datetime.datetime.strptime(s['firstTaskLaunchedTime'], \n",
    "                                                     \"%Y-%m-%dT%H:%M:%S.%fGMT\").timetuple())\n",
    "        completion_time = time.mktime(datetime.datetime.strptime(s['completionTime'], \n",
    "                                                     \"%Y-%m-%dT%H:%M:%S.%fGMT\").timetuple())\n",
    "        print(s['stageId'], s['inputBytes'], s['outputBytes'], s['rddIds'],\n",
    "              s['numTasks'], completion_time - submit_time)\n",
    "        \n",
    "        print(s.keys())\n",
    "        #break\n",
    "        \n",
    "for app in applications:\n",
    "    if app['name'] == 'name:wordcount-bw:40Gbps-ds:1G-stride:0-rep:0-jcxywltu':\n",
    "        get_stages(app['id'])\n",
    "        break\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''http://neu-3-1:18080/api/v1/applications/app-20200617160405-0036/stages'''\n",
    "'''http://neu-3-1:18080/api/v1/applications/app-20200617160405-0036/stages'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_str = '''+-(1) MapPartitionsRDD[120] at save at TpchQuery.scala:42 []\n",
    " |  ShuffledRowRDD[119] at save at TpchQuery.scala:42 []\n",
    " +-(200) MapPartitionsRDD[118] at save at TpchQuery.scala:42 []\n",
    "     |   MapPartitionsRDD[117] at save at TpchQuery.scala:42 []\n",
    "     |   MapPartitionsRDD[116] at save at TpchQuery.scala:42 []\n",
    "     |   MapPartitionsRDD[115] at save at TpchQuery.scala:42 []\n",
    "     |   ZippedPartitionsRDD2[114] at save at TpchQuery.scala:42 []\n",
    "     |   MapPartitionsRDD[76] at save at TpchQuery.scala:42 []\n",
    "     |   ShuffledRowRDD[75] at save at TpchQuery.scala:42 []\n",
    "     +-(200) MapPartitionsRDD[74] at save at TpchQuery.scala:42 []\n",
    "         |   MapPartitionsRDD[73] at save at TpchQuery.scala:42 []\n",
    "         |   ZippedPartitionsRDD2[72] at save at TpchQuery.scala:42 []\n",
    "         |   MapPartitionsRDD[36] at save at TpchQuery.scala:42 []\n",
    "         |   ShuffledRowRDD[35] at save at TpchQuery.scala:42 []\n",
    "         +-(128) MapPartitionsRDD[34] at save at TpchQuery.scala:42 []\n",
    "             |   MapPartitionsRDD[33] at save at TpchQuery.scala:42 []\n",
    "             |   MapPartitionsRDD[32] at save at TpchQuery.scala:42 []\n",
    "             |   MapPartitionsRDD[23] at map at TpchSchemaProvider.scala:105 []\n",
    "             |   MapPartitionsRDD[22] at map at TpchSchemaProvider.scala:105 []\n",
    "             |   /64G/part/part.tbl* MapPartitionsRDD[21] at textFile at TpchSchemaProvider.scala:105 []\n",
    "             |   /64G/part/part.tbl* HadoopRDD[20] at textFile at TpchSchemaProvider.scala:105 []\n",
    "         |   MapPartitionsRDD[71] at save at TpchQuery.scala:42 []\n",
    "         |   ShuffledRowRDD[70] at save at TpchQuery.scala:42 []\n",
    "         +-(200) MapPartitionsRDD[69] at save at TpchQuery.scala:42 []\n",
    "             |   MapPartitionsRDD[68] at save at TpchQuery.scala:42 []\n",
    "             |   ZippedPartitionsRDD2[67] at save at TpchQuery.scala:42 []\n",
    "             |   MapPartitionsRDD[61] at save at TpchQuery.scala:42 []\n",
    "             |   ShuffledRowRDD[60] at save at TpchQuery.scala:42 []\n",
    "             +-(200) MapPartitionsRDD[59] at save at TpchQuery.scala:42 []\n",
    "                 |   MapPartitionsRDD[58] at save at TpchQuery.scala:42 []\n",
    "                 |   ZippedPartitionsRDD2[57] at save at TpchQuery.scala:42 []\n",
    "                 |   MapPartitionsRDD[51] at save at TpchQuery.scala:42 []\n",
    "                 |   ShuffledRowRDD[50] at save at TpchQuery.scala:42 []\n",
    "                 +-(200) MapPartitionsRDD[49] at save at TpchQuery.scala:42 []\n",
    "                     |   MapPartitionsRDD[48] at save at TpchQuery.scala:42 []\n",
    "                     |   ZippedPartitionsRDD2[47] at save at TpchQuery.scala:42 []\n",
    "                     |   MapPartitionsRDD[41] at save at TpchQuery.scala:42 []\n",
    "                     |   ShuffledRowRDD[40] at save at TpchQuery.scala:42 []\n",
    "                     +-(2) MapPartitionsRDD[39] at save at TpchQuery.scala:42 []\n",
    "                        |  MapPartitionsRDD[38] at save at TpchQuery.scala:42 []\n",
    "                        |  MapPartitionsRDD[37] at save at TpchQuery.scala:42 []\n",
    "                        |  MapPartitionsRDD[15] at map at TpchSchemaProvider.scala:99 []\n",
    "                        |  MapPartitionsRDD[14] at map at TpchSchemaProvider.scala:99 []\n",
    "                        |  /64G/region/region.tbl* MapPartitionsRDD[13] at textFile at TpchSchemaProvider.scala:99 []\n",
    "                        |  /64G/region/region.tbl* HadoopRDD[12] at textFile at TpchSchemaProvider.scala:99 []\n",
    "                     |   MapPartitionsRDD[46] at save at TpchQuery.scala:42 []\n",
    "                     |   ShuffledRowRDD[45] at save at TpchQuery.scala:42 []\n",
    "                     +-(2) MapPartitionsRDD[44] at save at TpchQuery.scala:42 []\n",
    "                        |  MapPartitionsRDD[43] at save at TpchQuery.scala:42 []\n",
    "                        |  MapPartitionsRDD[42] at save at TpchQuery.scala:42 []\n",
    "                        |  MapPartitionsRDD[11] at map at TpchSchemaProvider.scala:96 []\n",
    "                        |  MapPartitionsRDD[10] at map at TpchSchemaProvider.scala:96 []\n",
    "                        |  /64G/nation/nation.tbl* MapPartitionsRDD[9] at textFile at TpchSchemaProvider.scala:96 []\n",
    "                        |  /64G/nation/nation.tbl* HadoopRDD[8] at textFile at TpchSchemaProvider.scala:96 []\n",
    "                 |   MapPartitionsRDD[56] at save at TpchQuery.scala:42 []\n",
    "                 |   ShuffledRowRDD[55] at save at TpchQuery.scala:42 []\n",
    "                 +-(128) MapPartitionsRDD[54] at save at TpchQuery.scala:42 []\n",
    "                     |   MapPartitionsRDD[53] at save at TpchQuery.scala:42 []\n",
    "                     |   MapPartitionsRDD[52] at save at TpchQuery.scala:42 []\n",
    "                     |   MapPartitionsRDD[31] at map at TpchSchemaProvider.scala:111 []\n",
    "                     |   MapPartitionsRDD[30] at map at TpchSchemaProvider.scala:111 []\n",
    "                     |   /64G/supplier/supplier.tbl* MapPartitionsRDD[29] at textFile at TpchSchemaProvider.scala:111 []\n",
    "                     |   /64G/supplier/supplier.tbl* HadoopRDD[28] at textFile at TpchSchemaProvider.scala:111 []\n",
    "             |   MapPartitionsRDD[66] at save at TpchQuery.scala:42 []\n",
    "             |   ShuffledRowRDD[65] at save at TpchQuery.scala:42 []\n",
    "             +-(128) MapPartitionsRDD[64] at save at TpchQuery.scala:42 []\n",
    "                 |   MapPartitionsRDD[63] at save at TpchQuery.scala:42 []\n",
    "                 |   MapPartitionsRDD[62] at save at TpchQuery.scala:42 []\n",
    "                 |   MapPartitionsRDD[27] at map at TpchSchemaProvider.scala:108 []\n",
    "                 |   MapPartitionsRDD[26] at map at TpchSchemaProvider.scala:108 []\n",
    "                 |   /64G/partsupp/partsupp.tbl* MapPartitionsRDD[25] at textFile at TpchSchemaProvider.scala:108 []\n",
    "                 |   /64G/partsupp/partsupp.tbl* HadoopRDD[24] at textFile at TpchSchemaProvider.scala:108 []\n",
    "     |   MapPartitionsRDD[113] at save at TpchQuery.scala:42 []\n",
    "     |   ShuffledRowRDD[112] at save at TpchQuery.scala:42 []\n",
    "     +-(200) MapPartitionsRDD[111] at save at TpchQuery.scala:42 []\n",
    "         |   MapPartitionsRDD[110] at save at TpchQuery.scala:42 []\n",
    "         |   ZippedPartitionsRDD2[109] at save at TpchQuery.scala:42 []\n",
    "         |   MapPartitionsRDD[81] at save at TpchQuery.scala:42 []\n",
    "         |   ShuffledRowRDD[80] at save at TpchQuery.scala:42 []\n",
    "         +-(128) MapPartitionsRDD[79] at save at TpchQuery.scala:42 []\n",
    "             |   MapPartitionsRDD[78] at save at TpchQuery.scala:42 []\n",
    "             |   MapPartitionsRDD[77] at save at TpchQuery.scala:42 []\n",
    "             |   MapPartitionsRDD[23] at map at TpchSchemaProvider.scala:105 []\n",
    "             |   MapPartitionsRDD[22] at map at TpchSchemaProvider.scala:105 []\n",
    "             |   /64G/part/part.tbl* MapPartitionsRDD[21] at textFile at TpchSchemaProvider.scala:105 []\n",
    "             |   /64G/part/part.tbl* HadoopRDD[20] at textFile at TpchSchemaProvider.scala:105 []\n",
    "         |   MapPartitionsRDD[108] at save at TpchQuery.scala:42 []\n",
    "         |   ShuffledRowRDD[107] at save at TpchQuery.scala:42 []\n",
    "         +-(200) MapPartitionsRDD[106] at save at TpchQuery.scala:42 []\n",
    "             |   MapPartitionsRDD[105] at save at TpchQuery.scala:42 []\n",
    "             |   ZippedPartitionsRDD2[104] at save at TpchQuery.scala:42 []\n",
    "             |   MapPartitionsRDD[102] at save at TpchQuery.scala:42 []\n",
    "             |   ShuffledRowRDD[101] at save at TpchQuery.scala:42 []\n",
    "             +-(200) MapPartitionsRDD[100] at save at TpchQuery.scala:42 []\n",
    "                 |   MapPartitionsRDD[99] at save at TpchQuery.scala:42 []\n",
    "                 |   ZippedPartitionsRDD2[98] at save at TpchQuery.scala:42 []\n",
    "                 |   MapPartitionsRDD[92] at save at TpchQuery.scala:42 []\n",
    "                 |   ShuffledRowRDD[91] at save at TpchQuery.scala:42 []\n",
    "                 +-(200) MapPartitionsRDD[90] at save at TpchQuery.scala:42 []\n",
    "                     |   MapPartitionsRDD[89] at save at TpchQuery.scala:42 []\n",
    "                     |   ZippedPartitionsRDD2[88] at save at TpchQuery.scala:42 []\n",
    "                     |   MapPartitionsRDD[82] at save at TpchQuery.scala:42 []\n",
    "                     |   ShuffledRowRDD[40] at save at TpchQuery.scala:42 []\n",
    "                     +-(2) MapPartitionsRDD[39] at save at TpchQuery.scala:42 []\n",
    "                        |  MapPartitionsRDD[38] at save at TpchQuery.scala:42 []\n",
    "                        |  MapPartitionsRDD[37] at save at TpchQuery.scala:42 []\n",
    "                        |  MapPartitionsRDD[15] at map at TpchSchemaProvider.scala:99 []\n",
    "                        |  MapPartitionsRDD[14] at map at TpchSchemaProvider.scala:99 []\n",
    "                        |  /64G/region/region.tbl* MapPartitionsRDD[13] at textFile at TpchSchemaProvider.scala:99 []\n",
    "                        |  /64G/region/region.tbl* HadoopRDD[12] at textFile at TpchSchemaProvider.scala:99 []\n",
    "                     |   MapPartitionsRDD[87] at save at TpchQuery.scala:42 []\n",
    "                     |   ShuffledRowRDD[86] at save at TpchQuery.scala:42 []\n",
    "                     +-(2) MapPartitionsRDD[85] at save at TpchQuery.scala:42 []\n",
    "                        |  MapPartitionsRDD[84] at save at TpchQuery.scala:42 []\n",
    "                        |  MapPartitionsRDD[83] at save at TpchQuery.scala:42 []\n",
    "                        |  MapPartitionsRDD[11] at map at TpchSchemaProvider.scala:96 []\n",
    "                        |  MapPartitionsRDD[10] at map at TpchSchemaProvider.scala:96 []\n",
    "                        |  /64G/nation/nation.tbl* MapPartitionsRDD[9] at textFile at TpchSchemaProvider.scala:96 []\n",
    "                        |  /64G/nation/nation.tbl* HadoopRDD[8] at textFile at TpchSchemaProvider.scala:96 []\n",
    "                 |   MapPartitionsRDD[97] at save at TpchQuery.scala:42 []\n",
    "                 |   ShuffledRowRDD[96] at save at TpchQuery.scala:42 []\n",
    "                 +-(128) MapPartitionsRDD[95] at save at TpchQuery.scala:42 []\n",
    "                     |   MapPartitionsRDD[94] at save at TpchQuery.scala:42 []\n",
    "                     |   MapPartitionsRDD[93] at save at TpchQuery.scala:42 []\n",
    "                     |   MapPartitionsRDD[31] at map at TpchSchemaProvider.scala:111 []\n",
    "                     |   MapPartitionsRDD[30] at map at TpchSchemaProvider.scala:111 []\n",
    "                     |   /64G/supplier/supplier.tbl* MapPartitionsRDD[29] at textFile at TpchSchemaProvider.scala:111 []\n",
    "                     |   /64G/supplier/supplier.tbl* HadoopRDD[28] at textFile at TpchSchemaProvider.scala:111 []\n",
    "             |   MapPartitionsRDD[103] at save at TpchQuery.scala:42 []\n",
    "             |   ShuffledRowRDD[65] at save at TpchQuery.scala:42 []\n",
    "             +-(128) MapPartitionsRDD[64] at save at TpchQuery.scala:42 []\n",
    "                 |   MapPartitionsRDD[63] at save at TpchQuery.scala:42 []\n",
    "                 |   MapPartitionsRDD[62] at save at TpchQuery.scala:42 []\n",
    "                 |   MapPartitionsRDD[27] at map at TpchSchemaProvider.scala:108 []\n",
    "                 |   MapPartitionsRDD[26] at map at TpchSchemaProvider.scala:108 []\n",
    "                 |   /64G/partsupp/partsupp.tbl* MapPartitionsRDD[25] at textFile at TpchSchemaProvider.scala:108 []\n",
    "                 |   /64G/partsupp/partsupp.tbl* HadoopRDD[24] at textFile at TpchSchemaProvider.scala:108 []'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "{\n",
      "          \"MapPartitionsRDD[58]\": {\n",
      "                    \"MapPartitionsRDD[56]\": {\n",
      "                              \"MapPartitionsRDD[44]\": {\n",
      "                                        \"MapPartitionsRDD[34]\": \"42 [] 9\",\n",
      "                                        \"MapPartitionsRDD[39]\": \"42 [] 9\"\n",
      "                              },\n",
      "                              \"MapPartitionsRDD[49]\": \"42 [] 5\"\n",
      "                    }\n",
      "          }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "class Stage():\n",
    "    def __init__(self, indent):\n",
    "        self.id = -1\n",
    "        self.parents = {}\n",
    "        self.children = {}\n",
    "        self.indent = indent\n",
    "        self.lines = []\n",
    "\n",
    "stages = []\n",
    "\n",
    "def _parse_rdd_string(rdd_str):\n",
    "    lines = rdd_str.split('\\n')\n",
    "    \n",
    "    n_stages = 0\n",
    "    prev_indent = -1\n",
    "    cur_stage = None\n",
    "    \n",
    "    for ln in lines:\n",
    "        if '+-' in n:\n",
    "            s = Stage(ln.index('+-'))\n",
    "            s.stage_id = len(stages)\n",
    "            stages.append(s)\n",
    "            \n",
    "            if cur_stage and cur_stage.indent < s.indent:\n",
    "                cur_stage.parents[s.id] = cur_stage\n",
    "            elif cur_stage and cur_stage.indent == s.indent:\n",
    "                pass\n",
    "            print(ln, ln.index('+-'))\n",
    "            n_stages += 1\n",
    "    print(n_stages)\n",
    "\n",
    "def parse_rdd_string(rdd_str):\n",
    "    lines = rdd_str.split('\\n')\n",
    "    \n",
    "    rdd_str = '''+-(1) MapPartitionsRDD[58] at save at TpchQuery.scala:42 []\n",
    " |  ShuffledRowRDD[57] at save at TpchQuery.scala:42 []\n",
    " +-(200) MapPartitionsRDD[56] at save at TpchQuery.scala:42 []\n",
    "     |   MapPartitionsRDD[55] at save at TpchQuery.scala:42 []\n",
    "     |   MapPartitionsRDD[54] at save at TpchQuery.scala:42 []\n",
    "     |   MapPartitionsRDD[53] at save at TpchQuery.scala:42 []\n",
    "     |   ZippedPartitionsRDD2[52] at save at TpchQuery.scala:42 []\n",
    "     |   MapPartitionsRDD[46] at save at TpchQuery.scala:42 []\n",
    "     |   ShuffledRowRDD[45] at save at TpchQuery.scala:42 []\n",
    "     +-(200) MapPartitionsRDD[44] at save at TpchQuery.scala:42 []\n",
    "         |   MapPartitionsRDD[43] at save at TpchQuery.scala:42 []\n",
    "         |   ZippedPartitionsRDD2[42] at save at TpchQuery.scala:42 []\n",
    "         |   MapPartitionsRDD[36] at save at TpchQuery.scala:42 []\n",
    "         |   ShuffledRowRDD[35] at save at TpchQuery.scala:42 []\n",
    "         +-(128) MapPartitionsRDD[34] at save at TpchQuery.scala:42 []\n",
    "             |   MapPartitionsRDD[33] at save at TpchQuery.scala:42 []\n",
    "             |   MapPartitionsRDD[32] at save at TpchQuery.scala:42 []\n",
    "             |   MapPartitionsRDD[3] at map at TpchSchemaProvider.scala:90 []\n",
    "             |   MapPartitionsRDD[2] at map at TpchSchemaProvider.scala:90 []\n",
    "             |   /64G/customer/customer.tbl* MapPartitionsRDD[1] at textFile at TpchSchemaProvider.scala:90 []\n",
    "             |   /64G/customer/customer.tbl* HadoopRDD[0] at textFile at TpchSchemaProvider.scala:90 []\n",
    "         |   MapPartitionsRDD[41] at save at TpchQuery.scala:42 []\n",
    "         |   ShuffledRowRDD[40] at save at TpchQuery.scala:42 []\n",
    "         +-(128) MapPartitionsRDD[39] at save at TpchQuery.scala:42 []\n",
    "             |   MapPartitionsRDD[38] at save at TpchQuery.scala:42 []\n",
    "             |   MapPartitionsRDD[37] at save at TpchQuery.scala:42 []\n",
    "             |   MapPartitionsRDD[19] at map at TpchSchemaProvider.scala:102 []\n",
    "             |   MapPartitionsRDD[18] at map at TpchSchemaProvider.scala:102 []\n",
    "             |   /64G/orders/orders.tbl* MapPartitionsRDD[17] at textFile at TpchSchemaProvider.scala:102 []\n",
    "             |   /64G/orders/orders.tbl* HadoopRDD[16] at textFile at TpchSchemaProvider.scala:102 []\n",
    "     |   MapPartitionsRDD[51] at save at TpchQuery.scala:42 []\n",
    "     |   ShuffledRowRDD[50] at save at TpchQuery.scala:42 []\n",
    "     +-(384) MapPartitionsRDD[49] at save at TpchQuery.scala:42 []\n",
    "         |   MapPartitionsRDD[48] at save at TpchQuery.scala:42 []\n",
    "         |   MapPartitionsRDD[47] at save at TpchQuery.scala:42 []\n",
    "         |   MapPartitionsRDD[7] at map at TpchSchemaProvider.scala:93 []\n",
    "         |   MapPartitionsRDD[6] at map at TpchSchemaProvider.scala:93 []\n",
    "         |   /64G/lineitem/lineitem.tbl* MapPartitionsRDD[5] at textFile at TpchSchemaProvider.scala:93 []\n",
    "         |   /64G/lineitem/lineitem.tbl* HadoopRDD[4] at textFile at TpchSchemaProvider.scala:93 []'''\n",
    "    \n",
    "    n_stages = 0\n",
    "    s = None\n",
    "    for idx, ln in enumerate(lines):\n",
    "        if '+-' in ln:\n",
    "            s = Stage(ln.index('+-'))\n",
    "            s.stage_id = len(stages)\n",
    "            stages.append(s)\n",
    "            lines[idx] = lines[idx] + \" \" + str(ln.index('+-'))\n",
    "        if s:\n",
    "            s.lines.append(ln)\n",
    "    lns = []\n",
    "    for ln in lines:\n",
    "        if '+-' in ln:\n",
    "            splits = ln.split(':')\n",
    "            name = 'MapPartitionsRDD[' + splits[0].split('MapPartitionsRDD')[1].split(']')[0].split('[')[1] + ']'\n",
    "            val = splits[1]\n",
    "            lns.append({'name': name, 'value': val, 'level': tab_level(ln)})\n",
    "            n_stages += 1\n",
    "    \n",
    "    print(n_stages)\n",
    "    return lns\n",
    "\n",
    "def build_dag(lines):\n",
    "    lns = []\n",
    "    \n",
    "\n",
    "def ttree_to_json(ttree,level=0):\n",
    "    result = {}\n",
    "    for i in range(0,len(ttree)):\n",
    "        cn = ttree[i]\n",
    "        try:\n",
    "            nn  = ttree[i+1]\n",
    "        except:\n",
    "            nn = {'level':-1}\n",
    "\n",
    "        # Edge cases\n",
    "        if cn['level']>level:\n",
    "            continue\n",
    "        if cn['level']<level:\n",
    "            return result\n",
    "\n",
    "        # Recursion\n",
    "        if nn['level']==level:\n",
    "            dict_insert_or_append(result,cn['name'],cn['value'])\n",
    "        elif nn['level']>level:\n",
    "            rr = ttree_to_json(ttree[i+1:], level=nn['level'])\n",
    "            dict_insert_or_append(result,cn['name'],rr)\n",
    "        else:\n",
    "            dict_insert_or_append(result,cn['name'],cn['value'])\n",
    "            return result\n",
    "    return result\n",
    "    \n",
    "    \n",
    "def ttree_to_json(ttree,level=0):\n",
    "    result = {}\n",
    "    for i in range(0,len(ttree)):\n",
    "        cn = ttree[i]\n",
    "        try:\n",
    "            nn  = ttree[i+1]\n",
    "        except:\n",
    "            nn = {'level':-1}\n",
    "\n",
    "        # Edge cases\n",
    "        if cn['level']>level:\n",
    "            continue\n",
    "        if cn['level']<level:\n",
    "            return result\n",
    "\n",
    "        # Recursion\n",
    "        if nn['level']==level:\n",
    "            dict_insert_or_append(result,cn['name'],cn['value'])\n",
    "        elif nn['level']>level:\n",
    "            rr = ttree_to_json(ttree[i+1:], level=nn['level'])\n",
    "            dict_insert_or_append(result,cn['name'],rr)\n",
    "        else:\n",
    "            dict_insert_or_append(result,cn['name'],cn['value'])\n",
    "            return result\n",
    "    return result    \n",
    "    \n",
    "def dict_insert_or_append(adict,key,val):\n",
    "    \"\"\"Insert a value in dict at key if one does not exist\n",
    "    Otherwise, convert value to list and append\n",
    "    \"\"\"\n",
    "    if key in adict:\n",
    "        if type(adict[key]) != list:\n",
    "            adict[key] = [adict[key]]\n",
    "        adict[key].append(val)\n",
    "    else:\n",
    "        adict[key] = val\n",
    "    \n",
    "def tab_level(astr):\n",
    "    \"\"\"Count number of leading tabs in a string\n",
    "    \"\"\"\n",
    "    ret = len(astr)- len(astr.lstrip(' '))\n",
    "    \n",
    "    return (ret - 1)//4 + 1 if ret > 1 else ret \n",
    "    \n",
    "lines = parse_rdd_string(rdd_str)\n",
    "ret = ttree_to_json(lines)\n",
    "\n",
    "print(json.dumps(ret, indent=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graph_tool.all as gt\n",
    "\n",
    "def build_graph(g, ret):\n",
    "    print(g)\n",
    "    for node_name in ret:\n",
    "        v = g.add_vertex()\n",
    "        g.vp.name[v] = node_name \n",
    "    \n",
    "g = gt.Graph(directed=True)\n",
    "build_graph(g, ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
